# Mutual Reinforcement Effect
### Universal Sentiment Analysis (USA Model)
### General Information Extraction Large Language Model (GIELLM)
### Open-domain Information Extraction Large Language Model (OIELLM)
### MMM: Multilingual Mutual Reinforcement Effect Mix Datasets


Model and Dataset. You can find in HuggingFace[https://huggingface.co/ganchengguang/OIELLM-8B-Instruction].

This is train and evaluation code.


# The project's website under construction, not yet completed. You can try dataset and model first please.


**Let me conclude by thanking the contributors to the MMM dataset for contributing the fundamental dataset. And the pioneering researchers who selflessly contributed.**

**1. Japanese Wikipedia NER dataset    Takahiro Omi  https://github.com/stockmarkteam/ner-wikipedia-dataset**

**2. JGLUE: Japanese General Language Understanding Evaluation    Kentaro Kurihara, Daisuke Kawahara, Tomohide Shibata   https://github.com/yahoojapan/JGLUE?tab=readme-ov-file**

**3. livedoor news corpus   関口宏司  https://www.rondhuit.com/download.html**

**4. UniversalNER    Wenxuan Zhou   https://arxiv.org/abs/2308.03279**




This webpage fork from https://github.com/nerfies/nerfies.github.io. Thank for they contribution.
```

# Website License
<a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-sa/4.0/88x31.png" /></a><br />This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike 4.0 International License</a>.
